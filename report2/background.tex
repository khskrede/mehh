
\chapter{Background}
\label{chap:back}

\section{Haskell}

% What is Haskell ?
Haskell is a lazy, pure functional language with non-strict semantics and static 
polymorphic typing. It provides user-defined algebraic datatypes, pattern-matching, 
list comprehensions, a system for modules, a system for monadic I/O, and a large 
standard library. In addition to beeing strongly typed, Haskell supports type
inference, which means type annotations are seldom required. Haskell is not described
in too much detail here, for a full description 
of Haskell, see "the Haskell 2010 language report"\cite{marlow2010haskell}. 
Or for a complete history of Haskell, see "A history of Haskell: being lazy 
with class"\cite{hudak2007history}.

Two specific features
of Haskell stand out: it is purely functional; this means that the functions 
can not have side-effects, or mutate data. For equal arguments, a function 
must provide equal results. The fact that Haskell is lazy refers to the techniques
used to evaluate a Haskell program, meaning that the arguments to a function are passed
unevaluated, and only evaluated when needed. Lazy semantics also means that impure 
non-functional language features are impossible, as the two cannot work in conjunction.
\cite{marlow2010haskell, marlow2012glasgow}

\section{PyPy}

% What is the PyPy project ?
PyPy is a project that shows the feasability of constructing a VM (Virtual Machine) 
for a dynamic  language in a dynamic language, specifically, Python. The PyPy 
environment aims to translate (i.e. compile) the VM into arbitrary targets. This 
means that an interpreter constructed in the PyPy environment will be able to 
run on any target supported by PyPy. Instead of writing multiple versions of 
the interpreter (one for C/Posix, JAVA, and one for CLI/.NET), it can be 
written in RPython, and translated to those back-ends. PyPy uses the 
"meta-programming" argument, if the VM can be written at a level of abstraction 
high enough, then it can be translated to any lower level platform. Implementing 
programming languages using a direct encoding approach is a complex task, and it 
usually results in an implementation that is specifically designed for a target platform. 
In effect this means that the implementation is not generic, and it is difficult to 
reuse the code for anything other than it's specific purpose. In contrast, 
PyPy's approach puts weight on portability and reusability\cite{pypy}. Although the
PyPy project puts most of its effort into its Python implementation, other projects
(such as a Prolog implementation \cite{bolz2010towards}) clearly shows the benefits of
such a generic approach.

% What is RPython and why is it used ?
The methods used by PyPy is to implement interpreters in RPython. RPython is a proper 
subset of Python (a RPython program can be executed by a Python interpreter) 
chosen such that it is possible to perform type inference on it. This
means that RPython programs can be translated into efficient C programs. Translating a 
program to C adds a number of implementation details that are not present in the RPython
implementation, such as a garbage collector. In addition to this, a tracing-JIT compiler 
can be added semi-automatically. This means that writing an interpreter in RPython containing
a tracing-JIT is much easier and less error-prone than implementing a specialized tracing-JIT
would be. 
\cite{bolz2011runtime}

% What is a JIT? TODO ???
PyPys tracing JIT is used to trace the execution of a number of languages implemented 
in RPython. In effect,
this JIT works on the meta-level, tracing the execution of the interpreter, and not the 
execution of the program being interpreted. The approach is called meta-tracing. In addition
to just tracing the meta-level, the RPython translator (the Python program that translates
RPython to C) allows for some annotations, speeding up the JIT. The efficiency of the 
resulting dynamic compiler relies on information fetched during runtime. Slowly changing 
variables is an example of such information, as it can be exploited by the compiler at 
run time by compiling multiple instances of code (one for each value of the variable),
resulting in faster code. \cite{bolz2011runtime}

% What is a tracing JIT ?
A tracing-JIT works by recording the execution of a program. The result is a set of 
traces of concrete execution, these traces are linear lists of operations. The lists of
operations are then optimized and turned into machine code. Among other benefits, the
result is free inlining of functions, as the functions operations are simply added to
the trace. \cite{bolz2011runtime}

\section{Haskell-Python}

% What is Haskell-Python ?
Haskell-Python\cite{haskellpython}
is an interpreter for a Haskell inspired lambda-calculs called Core'. 
It is meant to serve as the back-end for a complete Haskell compiler, after taking advantage 
of the front-end abilities of GHC. The interpreter notably has support for pattern matching 
and constructors. Our intent is to extend this interpreter into a full Haskell interpreter.
For more on Haskell-Python, see section \ref{chap:hs}.

% What is lambda-calculus ??? TODO

\section{GHC}

GHC is a 20 years old project, and it has been under development during
all these years. It started out with the goals of beeing a freely available
robust and portable compiler for Haskell, to provide a modular framework that
could be extended and developed by other researchers, and to learn how real
Haskell programs behave. \cite{marlow2012glasgow}

GHC can be divided into three parts, the compiler, the boot libraries
(libraries the compiler itself depends on) and the RTS (Runtime System). 
The compiler is the part
that turns Haskell source code into executable code. The boot libraries are the 
libraries that the compiler itself depends on. The RTS is a large library
of C code that is responsible for running the Haskell programs, such as the 
GC (Garbage Collector) implementation. The RTS system is linked into all 
Haskell programs compiled by GHC. These three parts corresponds to subdirectries
in the GHC source, namely "compiler", "libraries" and "rts".
\cite{marlow2012glasgow}

The compiler can also be divided into three parts. The Compilation Manager is 
responsible for the compilation of multiple Haskell source files. Its job is to
determine the order in which the files must be compiled. The Haskell Compiler 
(abbreviated "Hsc" inside GHC), handles the compilation of a single Haskell source
file. The Pipeline handles any preprocessing that is necessary, and the output
from Hsc is usually an assembly file that must be fed to an assembler.
\cite{marlow2012glasgow}

% TODO! THIS IS WHERE I STOPPED!

\subsection{GHC API}

% TODO
The compiler is (in addition to being a binary) itself a library that exports an API.
The GHC API was a goal from the beginning of its development, in the wording of
"being modular". A few notable projects have taken advantage of this modularity,
including a version of GHC containing a Lisp front-end, and a version that generates
Java code. With the growing popularity of Haskell, interest in tools that deal with
the language has increased. These tools need a lot of the functionality that is already
present in GHC. For this reason, GHC is built as a library, rather than a monolithic
program. The library is linked by a small Main module. In addition to this, GHC
exposes an API to deal with the library.\cite{marlow2012glasgow} 

\subsection{The Runtime System}

The RTS provides the support that is necessary for a Haskell program to run, this
includes; memory management, scheduling and thread management, primitive operations
and a bytecode interpreter and dynamic linker for GHCi (GHCs interactive environment).
\cite{marlow2012glasgow} 

\subsection{Core}

% TODO ???
Haskell is intended to be easy to read and write by humans. For this reason, it
incorporates a lot of syntactic constructs. This means that there are
usually many ways to write the same program. The definition of the Haskell language
defines these syntactic constructs in terms of their translation into simpler
constructs. Many of these syntactic constructs are thus in effect syntactic sugar.
After removing all of the syntactic suger (desugaring) GHC is left with a much 
simpler language. This language is called Core (or system $F_C$ when referring to
the theory).\cite{marlow2012glasgow} Core is discussed in more detail in chapter 
\ref{chap:rewrite}.

\subsection{External-Core and Linkcore}

% What is External-Core ?
GHC uses an intermediate language throughout it's 
simplification phase. The extcore project presents a formal definition of the syntax 
of this language. And in addition to this, enables the representation to be exported 
to files. The idea is that this allows compiler implementors and researchers to use GHC
as a front-end for Haskell compilers. Before outputting External-Core files,
the Haskell files are typechecked, desugared and simplified. \cite{tolmach2010ghc}

% What is linkcore ?
The linkcore project implements a linker for Core programs, i.e. it transforms
a single Haskell module into a single closed External-Core module. In addition to
this, since the linker requires External-Core representation of the ghc-libraries,
it also contains instructions on how to create these. 

% They have both bitrotted!
Unfortunately, at the time of this writing, both the External-Core and linkcore 
packages have bitrotted. Although there seems to be interest for the continued 
maintainance of External-Core.

\section{Similar work}

In addition to the Python implementation, PyPy implements a low-level 
hardware emulator (PyGirl), a PHP interpreter, a Prolog interpreter and various 
other experiments have been created by the PyPy team. 
%Prolog is a declarative programming language with roots in 
%formal logic, evaluation is performed when the user asks the program a question 
%(a query), and an evaluation algorithm  answers the question by using the program as
%a knowledge base.

\subsection{PyPy Prolog}

In addition to the implementation of Python, PyPy has also shown that its techniques
are applicable to other languages. The Prolog VM is an example of this. Implementations
of Prolog are usually written in low-level languages such as C, this usually results in
good performance, but means they are difficult to write and maintain. The PyPy Prolog 
interpreter clearly outperforms other Prolog interpreters written in other high-level
languages, and it also outperforms state-of-the-art Prolog VMs at specific benchmarks,
which shows that other Prolog implementations can benefit from the techniques used by
PyPy. \cite{bolz2010towards}

% TODO !
\subsection{HappyJIT}

PHP (Hypertext Preprocessor) is a language used to develop the server-side of 
websites. The users request for a website is received by the server, the PHP script
then executes the request, often involving querying a database and then generating 
the actual HTML for the user. Increasing the effectiveness of this process would
reduce the time it takes for a user to have a website request answered. 
The HappyJIT project implements a PHP interpreter in RPython, this interpreter is 
translated by the PyPy translator into a tracing-JIT. The approach show that 
the techniques significantly improve the performance of several common use cases.
\cite{homescu2011happyjit}

% TODO 
\subsection{PyGirl}

As a case study, PyGirl implements an emulater for the Nintendo Game Boy. The project 
shows the feasibility of implementing a low-level VM for hardware in a high-level 
language to improve portability, and reduce complexity. The project shows that the
reduction in implementation complexity with this approach is substantial, 
and that the performance loss can be insignificant.
\cite{bruni2009pygirl}

% TODO !
\subsection{The GHC LLVM back-end}

The LLVM (Low Level Virtual Machine) is a framework for the optimization of 
programs from the compilation phase to runtime. The LLVM provides high-level information 
to the compilation system during compile-time, run-time and in idle time between
runs. By creating codegenerators for the virtual instruction set supported by
LLVM, implementors can take full advantage of its features.
\cite{lattner2004llvm}

GHC can generate LLVM code from Cmm (C minus minus; is a low-level imperative
language with an explicit stack). In some cases the 
LLVM back-end can produce significantly faster code than the traditional route. 
\cite{marlow2012glasgow, terei2010llvm}

